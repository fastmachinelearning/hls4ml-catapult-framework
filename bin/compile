#!/usr/bin/python3
import subprocess
import os
import sys
import re
import argparse
from pathlib import Path

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Compile and test hls4ml '
                                     'Catapult projects.',
                                     epilog='Note that there is a special '
                                     'project called EntireTemplate which '
                                     'aims for checking the entire Catapult '
                                     'C++ backend code and does not have a test '
                                     'bench. You can compile it explicitly by '
                                     'specifying ID 0 with no --stress flag.')
    parser.add_argument('nums', metavar='ID', type=str,
                        nargs='*', help='the IDs of projects to be processed, '
                        'e.g. 1 2 3 will test Dense001, Dense002 and '
                        'Dense003 respectively. If not provided, all Dense '
                        ' projects (except stress ones) + EntireTemplate will '
                        'be processed.')
    parser.add_argument('--stress', action='store_true', dest='stress',
                        help='process stress projects (i.e. starting '
                        'with SDense) instead of standard ones (i.e. starting '
                        'with Dense). This will cause EntireTemplate not to be '
                        'processed.')
    parser.add_argument('--no-test', action='store_false', dest='do_test',
                        help='do not run test benches')

    args = parser.parse_args()
    
    os.chdir(str(Path(__file__).parent.parent))

    stress = args.stress
    do_test = args.do_test

    if len(args.nums) == 0:
        if args.stress:
            nums = []
            pattern = r'^SDense(\S+)$'
        else:
            nums = ['000']
            pattern = r'^Dense(\S+)$'

        for project in os.listdir('projects'):
            match = re.search(pattern, project)
            if match is not None:
                nums.append(match.group(1))

        nums.sort(key=lambda x: (len(x), x))
    else:
        nums = args.nums

    for i in range(len(nums)):
        digit_count = len(re.search(r'(\d+)', nums[i]).group(1))
        nums[i] = (3 - digit_count) * '0' + nums[i]

    if not os.path.exists('compile_logs'):
        os.makedirs('compile_logs')
    else:
        for entry in os.listdir('compile_logs'):
            os.remove(os.path.join('compile_logs', entry))

    errors = False

    for i in nums:
        name = f'Dense{i}' if i != '000' else 'EntireTemplate'

        if stress:
            if name == 'EntireTemplate':
                continue

            name = 'S' + name
        
        test = 1 if do_test and i != '000' else 0

        print(f'{name}... ', end='', flush=True)

        filename = None

        for cur_filename in os.listdir(os.path.join('projects', name)):
            if cur_filename.endswith('.ccs'):
                filename = cur_filename
                break

        if filename is None:
            filename = name + '.ccs'

        proc = subprocess.run(['singularity', 'exec',
                               '--env',
                               f'TCL_PROJECT_NAME={name}',
                               '--env',
                               f'TCL_PROJECT_PATH={name}/{filename}',
                               '--env',
                               f'TEST={test}',
                               'bin/catapult.sif',
                               'catapult', '-shell', '-file', 'bin/compile.tcl'],
                              stdout=subprocess.PIPE,
                              stderr=subprocess.STDOUT,
                              encoding='utf-8')

        with open(os.path.join('compile_logs', name + '.log'), 'w') as log_file:
            log_file.write(proc.stdout)

        if proc.returncode == 0:
            error_match = re.search('Error:.*make', proc.stdout)

            if error_match is not None:
                errors = True
                print('TEST FAIL')
            else:
                diff_match = \
                    re.search(r'{{LARGEST_RELATIVE_DIFFERENCE_OVERALL=(.+)}}',
                              proc.stdout)

                if diff_match is not None:
                    diff = float(diff_match.group(1))
                    against_zero_comparison_tests = \
                        len(re.findall(
                            '{{COMPARISON_AGAINST_ZERO_DETECTED}}', proc.stdout))

                    if diff >= 1.0:
                        status = 'TEST PROBLEM LIKELY'
                    elif against_zero_comparison_tests > 0:
                        status = 'AGAINST-ZERO COMPARISONS IN ' + \
                            str(against_zero_comparison_tests) + ' TEST(S)'
                    else:
                        status = 'OK'

                    print(status + f' (test largest error: {diff})')
                else:
                    print(f'OK (no testing run)')
        else:
            errors = True
            print('COMPILE FAIL')

    print()

    if errors:
        print('ERROR: Some models could not be compiled or tested!')
    else:
        print('SUCCESS: All models could be compiled and tested! You need to '
              'judge the testing results by hand.')

    print(f'See log files in "compile_logs" for more details.')

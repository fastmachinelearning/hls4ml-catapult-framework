#!/usr/bin/python3
import subprocess
import os
import sys
import re
import argparse
from io import StringIO
from pathlib import Path


class StringIOWithPrint(StringIO):
    def __init__(self, print_stdout):
        super().__init__()

        self._print_stdout = print_stdout

    def write(self, s):
        if self._print_stdout:
            sys.stdout.write(s)

        return super().write(s)

    def flush(self):
        if self._print_stdout:
            sys.stdout.flush()

        super().flush()


def run_cmd(command, log_file_name, cwd=None, env=None):
    # Set up environmental variables, having copied the existing ones from the OS
    if env is not None:
        os_env = os.environ.copy()
        os_env.update(env)
        env = os_env

    # Run the command
    proc = subprocess.run(command,
                          env=env,
                          cwd=cwd,
                          stdout=subprocess.PIPE,
                          stderr=subprocess.STDOUT,
                          encoding='utf-8')

    # Write the command output to the log file
    with open(os.path.join('synthesize_logs',
                           log_file_name + '.log'), 'w') as log_file:
        log_file.write(proc.stdout)

    # Return the exit code and the command output
    return proc.returncode, proc.stdout


def synthesis_vivado(solution_path: Path, name: str):
    # Run the Catapult-generated Vivado synthesis TCL script with
    # the power estimation command appended
    TO_APPEND = ['report_power -file $viv_report_dir/power.rpt']

    vivado_concat_vhdl = solution_path / 'vivado_concat_vhdl'
    synth = vivado_concat_vhdl / 'concat_rtl.vhdl.xv'

    with synth.open(mode='a') as f:
        f.write('\n')
        f.write('\n'.join(TO_APPEND))

    proc_returncode, _ = run_cmd(['vivado',
                                  '-mode',
                                  'batch',
                                  '-source',
                                  str(synth)],
                                 name + '_rtl_synth',
                                 cwd=vivado_concat_vhdl)

    if proc_returncode != 0:
        return None

    # Parse the reports generated by Vivado
    result = {}

    ## Parse the resource utilisation report
    utilization_report_path = vivado_concat_vhdl / 'utilization_synth.rpt'
    utilization_report = ''

    with utilization_report_path.open(mode='r') as f:
        for line in f:
            utilization_report += line

    slice_logic_regex_match = re.search(r'1\..+\n-+(.+)\* Warning',
                                        utilization_report,
                                        flags=re.DOTALL)
    slice_logic = slice_logic_regex_match.group(1)

    lut_regex_match = re.search(r'CLB LUTs[^\|]*\|\s*(\d+)', slice_logic,
                                flags=re.DOTALL)

    result['lut'] = lut_regex_match.group(1)

    ff_regex_match = re.search(r'Register as Flip Flop[^\|]*\|\s*(\d+)',
                               slice_logic, flags=re.DOTALL)
    result['ff'] = ff_regex_match.group(1)

    bram_regex_match = re.search(r'2\..+\n-+(.+)\* Note',
                                 utilization_report, flags=re.DOTALL)
    if not bram_regex_match:
        bram_regex_match = re.search(r'2\..+\n-+(.+)\n3\.',
                                     utilization_report, flags=re.DOTALL)

    bram = bram_regex_match.group(1)
    bram_specific_regex_match = re.search(r'Block RAM Tile[^\|]*\|\s*(\d+)',
                                          bram, flags=re.DOTALL)

    result['bram'] = bram_specific_regex_match.group(1)

    dsp_regex_match = re.search(r'\n3\..+\n-+(.+)\n4\.',
                                utilization_report, flags=re.DOTALL)
    dsp = dsp_regex_match.group(1)

    dsp_specific_regex_match = re.search(r'DSPs[^\|]*\|\s*(\d+)',
                                         dsp, flags=re.DOTALL)
    result['dsp'] = dsp_specific_regex_match.group(1)

    ## Parse the power estimation report
    power_report_path = vivado_concat_vhdl / 'power.rpt'
    power_report = ''

    with power_report_path.open(mode='r') as f:
        for line in f:
            power_report += line

    on_chip_regex_match = re.search(r'1\.1 On-Chip.+\n-+(.+)\n1\.2 Power Supply',
                                    power_report, flags=re.DOTALL)
    on_chip = on_chip_regex_match.group(1)

    clocks_regex_match = re.search(r'Clocks[^\|]*\|\s*([<>\d\.]+)', on_chip,
                                   flags=re.DOTALL)
    result['clocks_power'] = clocks_regex_match.group(1)

    logic_regex_match = re.search(r'CLB Logic[^\|]*\|\s*([<>\d\.]+)', on_chip,
                                  flags=re.DOTALL)
    result['logic_power'] = logic_regex_match.group(1)

    signals_regex_match = re.search(r'Signals[^\|]*\|\s*([<>\d\.]+)', on_chip,
                                    flags=re.DOTALL)
    result['signals_power'] = signals_regex_match.group(1)

    dsp_power_regex_match = re.search(r'DSPs[^\|]*\|\s*([<>\d\.]+)', on_chip,
                                      flags=re.DOTALL)
    result['dsp_power'] = dsp_power_regex_match.group(1)

    static_regex_match = re.search(r'Static Power[^\|]*\|\s*([<>\d\.]+)',
                                   on_chip, flags=re.DOTALL)
    result['static_power'] = static_regex_match.group(1)

    total_regex_match = re.search(r'Total[^\|]*\|\s*([<>\d\.]+)', on_chip,
                                  flags=re.DOTALL)
    result['total_power'] = total_regex_match.group(1)

    return result


def export_ip_vivado(solution_path: Path, ip_dest: Path, ip_name: str, name: str):
    # Append the IP packaging code to the Vivado "package_ip" TCL script
    # generated by Catapult. The code contains information about where
    # to store a ZIP file and how to name it.
    TO_APPEND = ['set rootDir $outputDir/..',
                 'ipx::package_project -root_dir $rootDir -vendor cern.ch '
                 '-library catapult -taxonomy /UserIP -force',
                 'ipx::create_xgui_files [ipx::current_core]',
                 'ipx::update_checksums [ipx::current_core]',
                 'ipx::save_core [ipx::current_core]',
                 'ipx::check_integrity -quiet [ipx::current_core]',
                 'ipx::archive_core $::env(DEST)/$::env(NAME).zip '
                 '[ipx::current_core]']

    vivado_concat_vhdl = solution_path / 'vivado_concat_vhdl'
    package_ip = vivado_concat_vhdl / 'concat_vhdl_package_ip.tcl'

    with package_ip.open(mode='a') as f:
        f.write('\n')
        f.write('\n'.join(TO_APPEND))

    # Create the destination directory
    ip_dest.mkdir(parents=True, exist_ok=True)

    # Run the updated "package_ip" TCL script
    proc_returncode, _ = run_cmd(['vivado',
                                  '-mode',
                                  'batch',
                                  '-source',
                                  str(package_ip)],
                                 name + '_ip_export',
                                 cwd=vivado_concat_vhdl,
                                 env={'DEST': str(ip_dest),
                                      'NAME': ip_name})

    return {} if proc_returncode == 0 else None


def synthesis_oasys(solution_path: Path, name: str):
    # Run the Catapult-generated Oasys-RTL synthesis script
    synth = solution_path / 'concat_rtl.vhdl.or'

    proc_returncode, report = run_cmd(['oasys',
                                       '-echo',
                                       str(synth),
                                       '-nogui'],
                                      name + '_rtl_synth',
                                      cwd=solution_path)

    if proc_returncode != 0:
        return None

    # Parse the area report produced by Oasys-RTL
    result = {}
    lines = report.split('\n')

    for i in range(len(lines) - 1, -1, -1):
        line = lines[i]
        area_match = re.search(
            r'Total Cell Area is ([\d\.]+)', line,
            flags=re.DOTALL)

        if area_match:
            result['area'] = area_match.group(1).strip()
            break

    return result

def get_rtl_activities(project_path: Path=None, tool: str=None):
    # Get tool-specific functions related to performing RTL (post-HLS)
    # activities. If the "tool" argument is not provided, the 02_libraries.tcl
    # file will be parsed to check which RTL tool should be used. Otherwise,
    # the functions specific to a tool with the provided name will be returned.
    #
    # If None is returned, a detected/provided RTL synthesis tool is not
    # supported by 'synthesize'.

    RTL_ACTIVITIES = {
        'Vivado': {
            'synthesize': synthesis_vivado,
            'export-ip': export_ip_vivado
        },
        'OasysRTL': {
            'synthesize': synthesis_oasys
        }
    }

    if tool is not None:
        return RTL_ACTIVITIES.get(tool)

    tcl_libraries_path = project_path / 'tcl' / '02_libraries.tcl'

    if not tcl_libraries_path.exists():
        return None

    tcl_libraries = ''

    with tcl_libraries_path.open(mode='r') as f:
        for line in f:
            tcl_libraries += line

    regex_match = re.search(r'[^#]*set RTL_SYN_TOOL (\S+)', tcl_libraries)

    if regex_match is None:
        return None

    return RTL_ACTIVITIES.get(regex_match.group(1))


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Synthesise hls4ml Catapult '
                                     'projects (i.e. run full HLS synthesis) '
                                     'and run optional RTL (post-HLS) '
                                     'activities.')

    # (*) If you want to change hls4ml Catapult project naming,
    # update the call below (e.g. the help message)
    parser.add_argument('nums', metavar='ID', type=str,
                        nargs='+', help='the IDs of projects to be processed, '
                        'e.g. 1 2 3 will synthesise Net0001, Net0002 and '
                        'Net0003 respectively (put \'all\' if you want to '
                        'process all projects)')

    parser.add_argument('--stress', action='store_true', dest='stress',
                        help='synthesise stress projects (i.e. starting '
                        'with SNet) instead of standard ones (i.e. starting '
                        'with Net)')
    parser.add_argument('--settings', metavar='ASSIGNS', dest='settings',
                        help='variables to be set for HLS synthesis purposes, '
                        'in the form of a comma-separated KEY=VALUE list '
                        '(e.g. "CLOCK_PERIOD=5.0,CLOCK_UNCERTAINTY=0.125")')
    parser.add_argument('--singularity', action='store_true',
                        dest='singularity', help='use the Singularity image '
                        'with Catapult (i.e. catapult.sif in "bin") instead of '
                        'the local installation')
    parser.add_argument('--csv', action='store_true', dest='csv',
                        help='do not print anything except for the HLS/RTL '
                        'synthesis results in form of CSV lines (one per '
                        'project)')
    parser.add_argument('--jobs', metavar='INT', type=int, dest='jobs',
                        default=1, help='the number of projects to be '
                        'processed in parallel (default: 1, note: if the value '
                        'is greater than 1, all outputs will be printed at the '
                        'end except for errors, which will be printed '
                        'instantaneously to STDERR)')

    rtl_group = parser.add_argument_group(title='arguments related to '
                                          'RTL (post-HLS) activities')
    rtl_group.add_argument('--rtl-synthesize', action='store_const',
                           const='synthesize', dest='rtl_activity',
                           help='run RTL synthesis after HLS synthesis is done')
    rtl_group.add_argument('--export-ip', metavar='DEST', dest='ip_dest',
                           help='export HLS-synthesised IPs to a specified '
                           'directory (it will be created if it does not exist)')

    args = parser.parse_args()

    os.chdir(str(Path(__file__).parent.parent))

    rtl_activities = None

    # Parse --singularity
    singularity = args.singularity

    # Parse --csv
    csv = args.csv

    # Parse --settings
    if args.settings is None:
        settings = [] if singularity else {}
    else:
        assigns = args.settings.split(',')

        # If RTL_SYN_TOOL is set in --settings, use its value for
        # get_rtl_activities() instead of what would be detected in
        # 02_libraries.tcl
        for assign in assigns:
            if assign.startswith('RTL_SYN_TOOL'):
                rtl_activities = get_rtl_activities(tool=assign.split('=')[1])
                break

        # When creating the 'settings' list, prepend all custom setting names
        # with "HLS_" so that they can be caught later on by the synthesize.tcl
        # script
        if singularity:
            settings = ['--env', ','.join(map(lambda x: 'HLS_' + x,
                                              args.settings.split(',')))]
        else:
            variables = args.settings.split(',')
            variables = map(lambda x: x.split('='), variables)

            settings = {'HLS_' + k: v for k, v in variables}

    # Parse --stress
    stress = args.stress

    # Parse --jobs
    jobs = args.jobs

    # Parse the provided project IDs
    nums = args.nums

    if len(nums) == 1 and nums[0] == 'all':
        nums = []

        # (*) If you want to change hls4ml Catapult project naming,
        # update the line below
        pattern = r'^SNet(\S+)$' if stress else r'^Net(\S+)$'

        for project in os.listdir('projects'):
            match = re.search(pattern, project)
            if match is not None:
                nums.append(match.group(1))

        nums.sort(key=lambda x: (len(x), x))

    # Add leading zeroes to the provided project IDs if necessary
    for i in range(len(nums)):
        digit_count = len(re.search(r'(\d+)', nums[i]).group(1))
        nums[i] = (4 - digit_count) * '0' + nums[i]

    # Prepare the 'synthesize_logs' directory
    if not os.path.exists('synthesize_logs'):
        os.makedirs('synthesize_logs')
    else:
        for entry in os.listdir('synthesize_logs'):
            os.remove(os.path.join('synthesize_logs', entry))

    # Process the projects
    def nums_loop(i, buf, rtl_activities):
        default_end = ',' if csv else '\n'
        stream = StringIOWithPrint(print_stdout=not buf)
        error = False

        def getvalue():
            return stream.getvalue() if buf else None

        # (*) If you want to change hls4ml Catapult project naming,
        # update the line below
        name = f'SNet{i}' if stress else f'Net{i}'

        project_path = Path('projects', name)

        # If RTL_SYN_TOOL is not set, detect what RTL tool should be used
        if rtl_activities is None:
            rtl_activities = get_rtl_activities(project_path)

            if rtl_activities is None:
                if buf or csv:
                    print(f'[stderr] {name}, could not determine the RTL '
                          'tool used, no RTL activities can be performed.',
                          file=sys.stderr, flush=True)
                else:
                    print(f'[{name}] warning, could not determine the RTL '
                          'tool used, no RTL activities can be performed.',
                          file=stream, end=default_end, flush=True)

        # Run the Catapult flow
        if csv:
            with (project_path / 'inputs.txt').open(mode='r') as f:
                inputs = f.readline().strip()

            print(','.join([name, inputs]), file=stream, end=default_end,
                  flush=True)
        else:
            print(f'[{name}] HLS synthesis...', file=stream, end=' ', flush=True)

        cmd_parts = ['catapult', '-shell', '-file',
                     'bin/synthesize.tcl']

        if singularity:
            cmd_parts = ['singularity', 'exec',
                         '--env',
                         f'MAIN_PATH={os.getcwd()},'
                         f'PROJECT_NAME={name},'
                         'TEST=0,'
                         'COMPILE_ONLY=0'] + settings + \
                         ['bin/catapult.sif'] + cmd_parts
            env = None
        else:
            env = settings
            env['MAIN_PATH'] = os.getcwd()
            env['PROJECT_NAME'] = name
            env['TEST'] = '0'
            env['COMPILE_ONLY'] = '0'

        proc_returncode, proc_out = run_cmd(cmd_parts, name, env=env)

        solution_path = Path('projects',
                             name,
                             name,
                             'synthesize.v1').absolute()

        hls_results = None
        synth_results = None
        impl_results = None
        export_ip_results = None

        if proc_returncode == 0:
            # Parse the cosimulation results
            cosim_match = \
                re.search(r'Info: scverify_top/user_tb: '
                          r'Simulation (PASSED|FAILED)',
                          proc_out)

            if cosim_match is not None:
                status = cosim_match.group(1)

                if status == 'PASSED':
                    print('OK', file=stream, end=default_end, flush=True)
                else:
                    print('COSIM PROBLEM LIKELY', file=stream, end=default_end,
                          flush=True)
            else:
                print('OK (no cosim run)', file=stream, end=default_end,
                      flush=True)

            # Parse the timing report
            regex_match = \
                re.search(r'Processes/Blocks in Design(.+)Timing Report',
                          proc_out,
                          flags=re.DOTALL)

            hls_results = regex_match.group(1)

            time_pred_regex_match = \
                re.search(r'Design Total:\s*\d+\s*(\d+)\s*(\d+)', hls_results,
                          flags=re.DOTALL)

            latency_pred = time_pred_regex_match.group(1)
            throughput_pred = time_pred_regex_match.group(2)

            power_expected = False

            static_power_regex_match = \
                re.search(r'Power Report \(uW\).*pre_pwropt_default_VHDL.*?'
                          r'Static'
                          r'\s*([\d\.]+)\s*([\d\.]+)\s*([\d\.]+)\s*([\d\.]+)\s*'
                          r'([\d\.]+)', hls_results, flags=re.DOTALL)

            if static_power_regex_match:
                power_expected = True

                memory_static_pwr = static_power_regex_match.group(1)
                reg_static_pwr = static_power_regex_match.group(2)
                comb_static_pwr = static_power_regex_match.group(3)
                clk_net_static_pwr = static_power_regex_match.group(5)
                total_static_pwr = static_power_regex_match.group(4)
            else:
                memory_static_pwr = None
                reg_static_pwr = None
                comb_static_pwr = None
                clk_net_static_pwr = None
                total_static_pwr = None

            dynamic_power_regex_match = \
                re.search(r'Power Report \(uW\).*pre_pwropt_default_VHDL.*?'
                          r'Dynamic'
                          r'\s*([\d\.]+)\s*([\d\.]+)\s*([\d\.]+)\s*([\d\.]+)\s*'
                          r'([\d\.]+)', hls_results, flags=re.DOTALL)

            if dynamic_power_regex_match:
                if not power_expected:
                    raise Exception('Dynamic power estimates found, but no '
                                    'power estimates are expected!')

                memory_dynamic_pwr = dynamic_power_regex_match.group(1)
                reg_dynamic_pwr = dynamic_power_regex_match.group(2)
                comb_dynamic_pwr = dynamic_power_regex_match.group(3)
                clk_net_dynamic_pwr = dynamic_power_regex_match.group(5)
                total_dynamic_pwr = dynamic_power_regex_match.group(4)
            elif power_expected:
                raise Exception('No dynamic power estimates found, but all '
                                'power estimates are expected!')
            else:
                memory_dynamic_pwr = None
                reg_dynamic_pwr = None
                comb_dynamic_pwr = None
                clk_net_dynamic_pwr = None
                total_dynamic_pwr = None

            power_regex_match = \
                re.search(r'Power Report \(uW\).*pre_pwropt_default_VHDL.*?Total'
                          r'\s*([\d\.]+)\s*([\d\.]+)\s*([\d\.]+)\s*([\d\.]+)\s*'
                          r'([\d\.]+)', hls_results, flags=re.DOTALL)

            if power_regex_match:
                if not power_expected:
                    raise Exception('Total power estimates found, but no '
                                    'power estimates are expected!')

                memory_pwr = power_regex_match.group(1)
                reg_pwr = power_regex_match.group(2)
                comb_pwr = power_regex_match.group(3)
                clk_net_pwr = power_regex_match.group(5)
                total_pwr = power_regex_match.group(4)
            elif power_expected:
                raise Exception('No total power estimates found, but all '
                                'power estimates are expected!')
            else:
                memory_pwr = None
                reg_pwr = None
                comb_pwr = None
                clk_net_pwr = None
                total_pwr = None

            clk_regex_match = \
                re.search(r'Info: scverify_top/Monitor: runs with constant '
                          r'clock period ([\d\.]+) ns', proc_out)
            throughput_regex_match = \
                re.search(r'Info: scverify_top/Monitor: Throughput: ([\d\.]+) '
                          r'transaction\S? per ([\d\.]+) ns', proc_out)
            latency_regex_match = \
                re.search(r'Info: scverify_top/Monitor: Latency: ([\d\.]+) ns',
                          proc_out)

            clock = clk_regex_match.group(1)
            throughput = float(throughput_regex_match.group(2)) / \
                float(throughput_regex_match.group(1))
            latency = latency_regex_match.group(1)

            if csv:
                print(','.join(filter(lambda x: x is not None,
                                      [latency_pred, throughput_pred,
                                       clock, latency, str(throughput),
                                       memory_static_pwr, reg_static_pwr,
                                       comb_static_pwr, clk_net_static_pwr,
                                       total_static_pwr,
                                       memory_dynamic_pwr, reg_dynamic_pwr,
                                       comb_dynamic_pwr, clk_net_dynamic_pwr,
                                       total_dynamic_pwr,
                                       memory_pwr, reg_pwr, comb_pwr,
                                       clk_net_pwr, total_pwr])),
                      end='' if rtl_activities is None or
                      args.rtl_activity != 'synthesize' else ',', file=stream,
                      flush=True)
            else:
                hls_results_str = \
                    '\n'.join(filter(lambda x: x is not None,
                                     [latency_pred, throughput_pred,
                                      memory_static_pwr, reg_static_pwr,
                                      comb_static_pwr, clk_net_static_pwr,
                                      total_static_pwr,
                                      memory_dynamic_pwr, reg_dynamic_pwr,
                                      comb_dynamic_pwr, clk_net_dynamic_pwr,
                                      total_dynamic_pwr,
                                      memory_pwr, reg_pwr, comb_pwr,
                                      clk_net_pwr, total_pwr]))

                print(hls_results_str, file=stream, end=default_end, flush=True)
                print('---', file=stream, end=default_end, flush=True)

                print('\n'.join([clock, latency, str(throughput)]), file=stream,
                      end=default_end, flush=True)
        else:
            error = True
            print('FAIL', end='', file=stream, flush=True)

            if buf:
                print(f'[stderr] {name}, HLS synthesis FAIL', file=sys.stderr,
                      flush=True)

            return getvalue(), error

        # Run specified RTL (post-HLS) activities if any
        if rtl_activities is not None and args.rtl_activity is not None:
            if args.rtl_activity == 'synthesize':
                if not csv:
                    print(f'[{name}] RTL synthesis...', end=' ', file=stream,
                          flush=True)

                synth_results = rtl_activities['synthesize'](solution_path, name)

                if synth_results is not None:
                    print('OK', file=stream, end=default_end, flush=True)
                    if csv:
                        print(','.join(synth_results.values()), file=stream,
                              end='', flush=True)
                    else:
                        for key, value in synth_results.items():
                            print((key, value), file=stream, end=default_end,
                                  flush=True)
                else:
                    error = True
                    print('FAIL', end='', file=stream, flush=True)

                    if buf:
                        print(f'[stderr] {name}, RTL synthesis FAIL',
                              file=sys.stderr, flush=True)

                    return getvalue(), error

        if args.ip_dest is not None:
            if not csv:
                print(f'[{name}] RTL IP export...', end=' ', file=stream,
                      flush=True)

            export_ip_results = \
                rtl_activities['export-ip'](solution_path,
                                            Path(args.ip_dest).absolute(),
                                            name, name)

            if export_ip_results is not None:
                if not csv:
                    print('OK', file=stream, end=default_end, flush=True)
            else:
                error = True
                if not csv:
                    print('FAIL', file=stream, end=default_end, flush=True)

                    if buf:
                        print(f'[stderr] {name}, RTL IP export FAIL',
                              file=sys.stderr, flush=True)

        return getvalue(), error

    errors = False

    if jobs == 1:
        for i in nums:
            _, error = nums_loop(i, False, rtl_activities)

            if error:
                errors = True

            print()
    else:
        from joblib import Parallel, delayed
        results = Parallel(n_jobs=jobs,
                           verbose=40)(delayed(nums_loop)(i, True,
                                                          rtl_activities)
                                       for i in nums)

        for _, error in results:
            if error:
                errors = True
                break

        print('\n'.join(map(lambda x: x[0], results)))

    # Done!
    if not csv:
        if errors:
            print('ERROR: Some or all operations have failed!')
        else:
            print('SUCCESS: All operations have been performed on all models '
                  'without problems!')

        print(f'See log files in "synthesize_logs" for more details.')
